{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import hardy.recognition.cnn as cnn\n",
    "import hardy.recognition.tuner as tuner\n",
    "from hardy.handling import pre_processing as preprocessing\n",
    "from hardy.handling import handling as handling\n",
    "from hardy.handling import to_catalogue as to_catalogue\n",
    "from hardy.hardy import classifier_wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_data = to_catalogue.save_load_data('../classifier_wrapper/rgb_Rex_Imy', file_extension='.npy', load=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path = '../classifier_wrapper/hardy/recognition/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set_filenames = preprocessing.hold_out_test_set(path='../200504_csv_EIS_simulation/', number_of_files_per_class=300,\n",
    "                                                     file_extension='.csv', classes=['noise', ''])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reloading Oracle from existing project ./tuner_run_9../classifier_wrapper/test_run_9/oracle.json\n",
      "INFO:tensorflow:Reloading Tuner from ./tuner_run_9../classifier_wrapper/test_run_9/tuner0.json\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "Confusion Matrix \n",
      "\n",
      "[[296   4]\n",
      " [ 39 260]]\n",
      "\n",
      " Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.99      0.93       300\n",
      "           1       0.98      0.87      0.92       299\n",
      "\n",
      "    accuracy                           0.93       599\n",
      "   macro avg       0.93      0.93      0.93       599\n",
      "weighted avg       0.93      0.93      0.93       599\n",
      "\n",
      "WARNING:tensorflow:From /Users/abdulmoeez/miniconda3/envs/direct/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1781: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "INFO:tensorflow:Assets written to: ../200504_csv_EIS_simulation/200605/tuner_run_9/../classifier_wrapper/test_run_9/best_model/assets\n"
     ]
    }
   ],
   "source": [
    "classifier_wrapper('../200504_csv_EIS_simulation/', test_set_filenames, '../classifier_wrapper/test_run_9',\n",
    "                   config_path, image_data=image_data, classifier='tuner',\n",
    "                   iterator_mode='arrays', split= 0.1, target_size= (80,80),\n",
    "                   batch_size=32, image_path=None,\n",
    "                   project_name='tuner_run_9')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_set_filenames = preprocessing.hold_out_test_set(path, number_of_files_per_class=500, classes=[])\n",
    "\n",
    "\n",
    "def classifier_wrapper(input_path, test_set_filenames, run_name, config_path, image_data=None,classifier='tuner',\n",
    "                       iterator_mode='arrays', split= 0.1, target_size= (80,80),\n",
    "                       batch_size=32, image_path=None, classes=['class_1','class_2'],\n",
    "                       project_name='tuner_run', **kwarg):\n",
    "    '''\n",
    "    \n",
    "    '''\n",
    "    if iterator_mode == 'arrays':\n",
    "        \n",
    "        assert image_data, 'No image_data list provided'\n",
    "        \n",
    "        test_set_list, learning_set_list = to_catalogue.data_set_split(image_data, test_set_filenames)\n",
    "        \n",
    "        training_set, validation_set = to_catalogue.learning_set(image_list=learning_set_list, split=split, target_size=target_size,\n",
    "                                                                 iterator_mode='arrays', batch_size=batch_size)\n",
    "        \n",
    "        test_set = to_catalogue.test_set(image_list=test_set_list, target_size=target_size,\n",
    "                                         iterator_mode='arrays', batch_size=batch_size)\n",
    "    else:\n",
    "        \n",
    "        assert image_path, 'no path to the image folders was provided'\n",
    "        \n",
    "        training_set, validation_set = to_catalogue.learning_set(image_path, plit=split, target_size=target_size,\n",
    "                                                                 iterator_mode='from_directory', batch_size=batch_size,\n",
    "                                                                 classes=classes)\n",
    "        print(validation_set)\n",
    "        test_set = to_catalogue.test_set(path, target_size=target_size,  classes=classes,\n",
    "                                         iterator_mode='from_directory', batch_size=batch_size,)\n",
    "    \n",
    "    if classifier == 'tuner':\n",
    "#         warn search_function, 'no search function provided, using default RandomSearch'\n",
    "        tuner.build_param(config_path)\n",
    "        tuner_model= tuner.run_tuner(training_set, validation_set, project_name= project_name + run_name)\n",
    "        model, history, metrics = tuner.best_model(tuner_model, training_set, validation_set, test_set)\n",
    "        output_path= preprocessing.save_to_folder(input_path, project_name, run_name)\n",
    "        conf_matrix, report = cnn.report_on_metrics(model, test_set) \n",
    "        tuner.report_generation(model, history, metrics, output_path , tuner=tuner_model, save_model=True)\n",
    "    else:\n",
    "        model, history = cnn.build_model(training_set, validation_set, config_path=config_path)\n",
    "        metrics = cnn.evaluate_model(model, test_set)\n",
    "\n",
    "        output_path= preprocessing.save_to_folder(input_path, project_name, run_name)\n",
    "        conf_matrix, report = cnn.report_on_metrics(model, test_set) \n",
    "        tuner.report_generation(model, history, metrics, output_path , tuner=None, save_model=True, config_path=config_path)\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import hardy.run_hardy as run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_path = '../eisy/examples/simulation_data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tform_config_path = './hardy/arbitrage/tform_config.yaml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_config_path = './hardy/recognition/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully Loaded 11 Transforms to Try!\n",
      "Processing Data...\tFrom 9002 Files:\n",
      "Found 9000 CSVs...\n",
      "Found 3 Labels, Only Expected 2...\n",
      "\t3500 Files of Label : one\n",
      "\t4500 Files of Label : noise\n",
      "\t1000 Files of Label : spread\n",
      "Loaded\t9000 of 9002\tFiles\t at rate of 112 Files per Second\n",
      "\t Success!\t About 1.34 Minutes...\n",
      "Making rgb Images from Data...\t"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-ca58e4022bcb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m run.hardy_multi_transform(raw_data_path, tform_config_path, classifier_config_path,\n\u001b[1;32m----> 2\u001b[1;33m                           iterator_mode='arrays', classes=['noise', ''], project_name='multi_transform')\n\u001b[0m",
      "\u001b[1;32m~\\Desktop\\DS_Class\\project\\hardy\\hardy\\run_hardy.py\u001b[0m in \u001b[0;36mhardy_multi_transform\u001b[1;34m(raw_datapath, tform_config_path, classifier_config_path, iterator_mode, plot_format, print_out, num_test_files_class, classifier, split, target_size, batch_size, classes, project_name)\u001b[0m\n\u001b[0;32m    118\u001b[0m                 \u001b[0mraw_datapath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtform_commands\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtform_commands\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m                 \u001b[0mplot_format\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mplot_format\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miterator_mode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0miterator_mode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 120\u001b[1;33m                 print_out=print_out)\n\u001b[0m\u001b[0;32m    121\u001b[0m             \u001b[0mimage_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    122\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\DS_Class\\project\\hardy\\hardy\\run_hardy.py\u001b[0m in \u001b[0;36mdata_wrapper\u001b[1;34m(raw_datapath, tform_commands, plot_format, iterator_mode, print_out)\u001b[0m\n\u001b[0;32m    178\u001b[0m     \u001b[1;31m# Next make the rgb images Tuples List\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    179\u001b[0m     rgb_tuples_list = to_catalogue.rgb_list(tform_tuples_list,\n\u001b[1;32m--> 180\u001b[1;33m                                             plot_format=plot_format)\n\u001b[0m\u001b[0;32m    181\u001b[0m     \u001b[1;31m# OK! Now we have image arrays finished!\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    182\u001b[0m     \u001b[1;31m#     EITHER Return that list of image tuples\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\DS_Class\\project\\hardy\\hardy\\handling\\to_catalogue.py\u001b[0m in \u001b[0;36mrgb_list\u001b[1;34m(data_tuples, plot_format, column_names, combine_method)\u001b[0m\n\u001b[0;32m    228\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    229\u001b[0m         rgb_image = rgb_visualize(fdata, plot_format, combine_method,\n\u001b[1;32m--> 230\u001b[1;33m                                   column_names)\n\u001b[0m\u001b[0;32m    231\u001b[0m         \u001b[1;31m# Need some check that the visualization worked?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    232\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\DS_Class\\project\\hardy\\hardy\\handling\\to_catalogue.py\u001b[0m in \u001b[0;36mrgb_visualize\u001b[1;34m(fdata, plot_format, combine_method, column_names)\u001b[0m\n\u001b[0;32m    357\u001b[0m             rgb_image = vis.orthogonal_images_add(rgb_image_x,\n\u001b[0;32m    358\u001b[0m                                                   \u001b[0mrgb_image_y\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 359\u001b[1;33m                                                   plot=False)\n\u001b[0m\u001b[0;32m    360\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mrgb_image\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    361\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\DS_Class\\project\\hardy\\hardy\\handling\\visualization.py\u001b[0m in \u001b[0;36morthogonal_images_add\u001b[1;34m(image_x, image_y, plot, save_image, filename, save_location)\u001b[0m\n\u001b[0;32m    209\u001b[0m         \u001b[0mimage_flip\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mchannel\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimage_y\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mchannel\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 211\u001b[1;33m     \u001b[0mcombined_image\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnormalize_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_x\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mimage_flip\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    212\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    213\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mplot\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\DS_Class\\project\\hardy\\hardy\\handling\\visualization.py\u001b[0m in \u001b[0;36mnormalize_image\u001b[1;34m(color_image_array)\u001b[0m\n\u001b[0;32m     64\u001b[0m             \u001b[1;31m# normalizing data per channel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m                 \u001b[1;32mif\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     67\u001b[0m                     \u001b[0mnormalized_image\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
     ]
    }
   ],
   "source": [
    "run.hardy_multi_transform(raw_data_path, tform_config_path, classifier_config_path,\n",
    "                          iterator_mode='arrays', classes=['noise', ''], project_name='multi_transform')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "image_labels = [ 'noisy', 'not_noisy', 'noisy', 'not_noisy' ,'noisy', 'extra']\n",
    "# image_data = [( 'file_1', [1,2,3,4], 'not_noisy'), ( 'file_2', [1,2,3,4], 'noisy'), ( 'file_3', [1,2,3,4], 'not_noisy'), ( 'file_4', [1,2,3,4], 'noisy')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['extra', 'noisy', 'not_noisy'], dtype='<U9')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(image_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 1, 2, 1, 0]\n"
     ]
    }
   ],
   "source": [
    "for i, label in enumerate(np.unique(image_labels)):\n",
    "    for j in range(len(image_labels)):\n",
    "        if image_labels[j]== label:\n",
    "            image_labels[j] = i\n",
    "        \n",
    "print(image_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_path = '../eisy/examples/simulation_data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
